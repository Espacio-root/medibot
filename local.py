# run locally
# ~/projects/llama.cpp/main -m ~/projects/text-generation-webui/models/medllama2_7b_q4_0.gguf -n 256 --repeat_penalty 1.0 --color -i -r "User:" -f ~/projects/llama.cpp/prompts/template.txt

# run text-generation-webui
# ~/projects/text-generation-webui/start_linux.sh


